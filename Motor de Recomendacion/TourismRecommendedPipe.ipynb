{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77dc959e-2f61-4005-8962-890c48414550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "from typing import Dict, List, Optional\n",
    "import argparse\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c42998-5d32-4b97-8140-02fb934545e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        physical_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3584)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9242d317-2796-4bf9-8857-b17cbf70f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('tourism_recommender_fast.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20fd11a-49be-4477-aef3-db1b4e2e197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TourismRecommenderPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline optimizado para RTX 3050 Ti\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        self.config = self._load_config(config_path)\n",
    "        self.db_path = self.config['database']['path']\n",
    "        self.model_path = self.config['model']['path']\n",
    "        self.data_paths = self.config['data_paths']\n",
    "        self.storage_path = self.config.get('storage_path', 'AI_Recomendador')\n",
    "        \n",
    "        # Estado del pipeline\n",
    "        self.last_training = None\n",
    "        self.last_data_update = None\n",
    "        \n",
    "        logging.info(\"Pipeline RTX 3050 Ti inicializado\")\n",
    "    \n",
    "    def _load_config(self, config_path: str) -> dict:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        return config\n",
    "    \n",
    "    def setup_database(self):\n",
    "        \"\"\"\n",
    "        BD optimizada para almacenar resultados compactos\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS recommendations_compact (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                user_id TEXT,\n",
    "                city TEXT,\n",
    "                item_id TEXT,\n",
    "                final_score REAL,\n",
    "                timestamp DATETIME,\n",
    "                boost_factors TEXT\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS model_metrics_compact (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                model_version TEXT,\n",
    "                timestamp DATETIME,\n",
    "                val_loss REAL,\n",
    "                val_accuracy REAL,\n",
    "                training_time_minutes REAL,\n",
    "                gpu_used BOOLEAN\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        logging.info(\"Base de datos compacta configurada\")\n",
    "    \n",
    "    def data_ingestion_and_processing_fast(self):\n",
    "        \"\"\"\n",
    "        Procesamiento r치pido optimizado\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        logging.info(\"Iniciando procesamiento r치pido de datos\")\n",
    "        \n",
    "        try:\n",
    "            # Importar clase optimizada\n",
    "            from fixed_data_prep_pipeline import TourismDataPreprocessor\n",
    "            \n",
    "            self.data_preprocessor = TourismDataPreprocessor()\n",
    "            \n",
    "            # Cargar datasets\n",
    "            datasets = self.data_preprocessor.load_and_clean_datasets(self.data_paths)\n",
    "            \n",
    "            # Procesamiento optimizado\n",
    "            processed_features, matched_reviews = self.data_preprocessor.prepare_deep_learning_features(datasets)\n",
    "            \n",
    "            # Crear matrices usando storage en disco\n",
    "            if not matched_reviews.empty:\n",
    "                sample_matrices = self.data_preprocessor.create_user_item_matrix(\n",
    "                    matched_reviews, datasets['activities'], storage_path=self.storage_path\n",
    "                )\n",
    "                \n",
    "                # Preparar datos de entrenamiento optimizados\n",
    "                training_sample, training_mappings = self.data_preprocessor.prepare_training_data_for_deep_learning(\n",
    "                    matched_reviews, storage_path=self.storage_path, sample_size=30000\n",
    "                )\n",
    "                \n",
    "                processed_data = {\n",
    "                    'city_features': processed_features,\n",
    "                    'user_item_matrix': sample_matrices[0],\n",
    "                    'user_sentiment_matrix': sample_matrices[1], \n",
    "                    'user_confidence_matrix': sample_matrices[2],\n",
    "                    'matched_reviews': matched_reviews,\n",
    "                    'training_sample': training_sample,\n",
    "                    'training_mappings': training_mappings,\n",
    "                    'raw_datasets': datasets\n",
    "                }\n",
    "                \n",
    "                # Guardado eficiente\n",
    "                self.data_preprocessor.save_processed_data_efficiently(\n",
    "                    processed_data, 'processed_tourism_data_fast.pkl', self.storage_path\n",
    "                )\n",
    "            else:\n",
    "                logging.warning(\"No se encontraron reviews emparejadas\")\n",
    "                return None\n",
    "            \n",
    "            self.last_data_update = datetime.now()\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            logging.info(f\"Procesamiento r치pido completado en {duration/60:.1f} minutos\")\n",
    "            return processed_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            duration = time.time() - start_time\n",
    "            logging.error(f\"Error en procesamiento: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def model_training_fast(self, processed_data: dict, retrain: bool = False):\n",
    "        \"\"\"\n",
    "        Entrenamiento optimizado para RTX 3050 Ti\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        logging.info(\"Iniciando entrenamiento optimizado para RTX 3050 Ti\")\n",
    "        \n",
    "        try:\n",
    "            # Verificar si necesita reentrenamiento\n",
    "            if not retrain and Path(self.model_path).exists():\n",
    "                if self.last_training and (datetime.now() - self.last_training).days < 3:\n",
    "                    logging.info(\"Modelo reciente encontrado, saltando entrenamiento\")\n",
    "                    return self._load_existing_model_fast()\n",
    "            \n",
    "            # Importar modelo optimizado\n",
    "            from deep_learning_recommender import TourismRecommenderModel\n",
    "            \n",
    "            # Configuraci칩n optimizada para RTX 3050 Ti\n",
    "            self.recommender_model = TourismRecommenderModel(\n",
    "                embedding_dim=32,    # Reducido para 4GB VRAM\n",
    "                dense_units=64       # Reducido para 4GB VRAM\n",
    "            )\n",
    "            \n",
    "            # Usar datos de entrenamiento ya preparados\n",
    "            training_data = processed_data.get('training_sample', pd.DataFrame())\n",
    "            training_mappings = processed_data.get('training_mappings', {})\n",
    "            \n",
    "            if training_data.empty:\n",
    "                raise ValueError(\"No hay datos de entrenamiento preparados\")\n",
    "            \n",
    "            # Preparar datos para el modelo\n",
    "            training_df = self.recommender_model.prepare_training_data({\n",
    "                'training_sample': training_data,\n",
    "                'training_mappings': training_mappings\n",
    "            })\n",
    "            \n",
    "            # Construir modelo compacto\n",
    "            num_users = len(training_mappings['user_to_idx'])\n",
    "            num_items = len(training_mappings['item_to_idx'])\n",
    "            num_cities = len(training_mappings['city_to_idx'])\n",
    "            \n",
    "            model = self.recommender_model.build_hybrid_model(\n",
    "                num_users=num_users,\n",
    "                num_items=num_items,\n",
    "                num_cities=num_cities,\n",
    "                contextual_features_dim=10,  # Reducido\n",
    "                weather_features_dim=15      # Reducido\n",
    "            )\n",
    "            \n",
    "            # Entrenamiento r치pido\n",
    "            logging.info(\"Iniciando entrenamiento con configuraci칩n RTX 3050 Ti...\")\n",
    "            \n",
    "            history = self.recommender_model.train_model(\n",
    "                training_df,\n",
    "                epochs=30,           # Reducido para velocidad\n",
    "                batch_size=128,      # 칍ptimo para 4GB VRAM\n",
    "                validation_split=0.2\n",
    "            )\n",
    "            \n",
    "            # Guardar modelo compacto\n",
    "            self.recommender_model.save_model(self.model_path)\n",
    "            \n",
    "            # M칠tricas\n",
    "            metrics = {\n",
    "                'val_loss': min(history.history['val_loss']),\n",
    "                'val_accuracy': max(history.history['val_interaction_accuracy']),\n",
    "                'training_time': (time.time() - start_time) / 60,\n",
    "                'gpu_used': True\n",
    "            }\n",
    "            \n",
    "            self._save_model_metrics_fast(metrics)\n",
    "            \n",
    "            self.last_training = datetime.now()\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            logging.info(f\"Entrenamiento completado en {duration/60:.1f} minutos\")\n",
    "            logging.info(f\"Mejor val_loss: {metrics['val_loss']:.4f}\")\n",
    "            \n",
    "            return self.recommender_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            duration = time.time() - start_time\n",
    "            logging.error(f\"Error en entrenamiento: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _load_existing_model_fast(self):\n",
    "        \"\"\"\n",
    "        Carga modelo existente de manera r치pida\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from deep_learning_recommender import TourismRecommenderModel\n",
    "            \n",
    "            # Cargar modelo\n",
    "            model = tf.keras.models.load_model(self.model_path)\n",
    "            \n",
    "            # Cargar mappings\n",
    "            mappings_path = Path(self.storage_path) / 'training_mappings_gpu_optimized.pkl'\n",
    "            with open(mappings_path, 'rb') as f:\n",
    "                mappings = pickle.load(f)\n",
    "            \n",
    "            # Recrear objeto\n",
    "            self.recommender_model = TourismRecommenderModel(embedding_dim=32, dense_units=64)\n",
    "            self.recommender_model.model = model\n",
    "            self.recommender_model.user_to_idx = mappings['user_to_idx']\n",
    "            self.recommender_model.item_to_idx = mappings['item_to_idx']\n",
    "            self.recommender_model.city_to_idx = mappings['city_to_idx']\n",
    "            \n",
    "            logging.info(\"Modelo existente cargado r치pidamente\")\n",
    "            return self.recommender_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error cargando modelo existente: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _save_model_metrics_fast(self, metrics: dict):\n",
    "        \"\"\"\n",
    "        Guarda m칠tricas de manera r치pida\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            INSERT INTO model_metrics_compact \n",
    "            (model_version, timestamp, val_loss, val_accuracy, training_time_minutes, gpu_used)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            f\"fast_v{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "            datetime.now(),\n",
    "            metrics.get('val_loss', 0),\n",
    "            metrics.get('val_accuracy', 0),\n",
    "            metrics.get('training_time', 0),\n",
    "            metrics.get('gpu_used', False)\n",
    "        ))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def run_fast_pipeline(self, retrain_model: bool = False):\n",
    "        \"\"\"\n",
    "        Ejecuta pipeline completo optimizado\n",
    "        \"\"\"\n",
    "        logging.info(\"=== INICIANDO PIPELINE R츼PIDO RTX 3050 Ti ===\")\n",
    "        \n",
    "        total_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # 1. Setup BD\n",
    "            self.setup_database()\n",
    "            \n",
    "            # 2. Procesamiento de datos\n",
    "            processed_data = self.data_ingestion_and_processing_fast()\n",
    "            \n",
    "            if processed_data is None:\n",
    "                logging.error(\"No se pudieron procesar los datos\")\n",
    "                return\n",
    "            \n",
    "            # 3. Entrenamiento del modelo\n",
    "            model = self.model_training_fast(processed_data, retrain=retrain_model)\n",
    "            \n",
    "            if model is None:\n",
    "                logging.error(\"No se pudo entrenar/cargar el modelo\")\n",
    "                return\n",
    "            \n",
    "            total_duration = time.time() - total_start_time\n",
    "            \n",
    "            logging.info(\"=== PIPELINE R츼PIDO COMPLETADO EXITOSAMENTE ===\")\n",
    "            logging.info(f\"Tiempo total: {total_duration/60:.1f} minutos\")\n",
    "            \n",
    "            # Estad칤sticas finales\n",
    "            training_sample = processed_data.get('training_sample', pd.DataFrame())\n",
    "            if not training_sample.empty:\n",
    "                logging.info(f\"Reviews de entrenamiento: {len(training_sample):,}\")\n",
    "                logging.info(f\"Usuarios: {training_sample['user_id'].nunique():,}\")\n",
    "                logging.info(f\"Items: {training_sample['item_id'].nunique():,}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            total_duration = time.time() - total_start_time\n",
    "            logging.error(f\"ERROR EN PIPELINE: {e}\")\n",
    "            logging.error(f\"Tiempo antes del error: {total_duration/60:.1f} minutos\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c618529-1d49-49ea-9667-352b1c2bb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Tourism Recommender Fast Pipeline')\n",
    "    parser.add_argument('--config', default='config_fast.json', help='Configuraci칩n')\n",
    "    parser.add_argument('--retrain', action='store_true', help='Forzar reentrenamiento')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Crear configuraci칩n optimizada si no existe\n",
    "    if not Path(args.config).exists():\n",
    "        default_config = {\n",
    "            \"database\": {\"path\": \"tourism_recommender_fast.db\"},\n",
    "            \"model\": {\"path\": \"tourism_model_rtx3050ti.h5\"},\n",
    "            \"storage_path\": \"AI_Recomendador\",\n",
    "            \"data_paths\": {\n",
    "                \"activities\": [\"activities_1.csv\", \"activities_2.csv\", \"activities_3.csv\", \n",
    "                              \"activities_4.csv\", \"activities_5.csv\"],\n",
    "                \"reviews\": \"sentiment_analysis_with_weather.csv\",\n",
    "                \"un_tourism\": [\"un_tourism_1.csv\", \"un_tourism_2.csv\", \"un_tourism_3.csv\",\n",
    "                              \"un_tourism_4.csv\", \"un_tourism_5.csv\", \"un_tourism_6.csv\", \n",
    "                              \"un_tourism_7.csv\"],\n",
    "                \"commuting_zones\": \"meta_commuting_zones.csv\",\n",
    "                \"movement_data\": \"meta_movement_data.csv\",\n",
    "                \"search_trends\": \"google_trends_searches.csv\",\n",
    "                \"monthly_interest\": \"google_trends_monthly_interest.csv\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(args.config, 'w') as f:\n",
    "            json.dump(default_config, f, indent=2)\n",
    "        \n",
    "        logging.info(f\"Configuraci칩n optimizada creada: {args.config}\")\n",
    "    \n",
    "    # Ejecutar pipeline r치pido\n",
    "    pipeline = TourismRecommenderPipeline(args.config)\n",
    "    \n",
    "    success = pipeline.run_fast_pipeline(retrain_model=args.retrain)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nPIPELINE R츼PIDO COMPLETADO CON 칄XITO!\")\n",
    "        print(\"Optimizado para RTX 3050 Ti\")\n",
    "        print(\"Modelo y datos guardados en disco\")\n",
    "        print(\"M칠tricas guardadas en BD\")\n",
    "    else:\n",
    "        print(\"\\nPIPELINE FALL칍 - Revisar logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966e7be-89d7-4a9f-8bd2-5501a91954dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "mi_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
